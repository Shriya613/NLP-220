# -*- coding: utf-8 -*-
"""220_A2_svm.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/153FP2CaZT8mFZW5UsyGUfeC5KVX7vjrg

BoW
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import accuracy_score, confusion_matrix, f1_score
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from time import time

from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer

data = pd.read_csv("ecommerceDataset.csv")

data.head(5)

data.info()

# Check for missing values and handle them if needed
print("Missing values per column:\n", data.isnull().sum())

# Dropping rows with missing values (if any exist)
data = data.dropna()

# Rename columns for clarity
data.columns = ['Category', 'Description']

# Display the first few rows of the updated dataframe
print("Updated dataset structure:\n", data.head())

# Plot the distribution of classes
plt.figure(figsize=(10, 6))
data['Category'].value_counts().plot(kind='bar')
plt.title("Distribution of Classes in the E-commerce Dataset")
plt.xlabel("Category")
plt.ylabel("Count")
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# Train/test split- 70% train, 10% validation, 20% test
train_data, temp_data = train_test_split(data, test_size=0.3, random_state=42, shuffle=True)
val_data, test_data = train_test_split(temp_data, test_size=2/3, random_state=42, shuffle=True)

# Display the distribution of the split data
print("Train class distribution:\n", train_data['Category'].value_counts())
print("Validation class distribution:\n", val_data['Category'].value_counts())
print("Test class distribution:\n", test_data['Category'].value_counts())

#CountVectorizer
from sklearn.feature_extraction.text import CountVectorizer
cv = CountVectorizer(max_features = 5000)
X_train_count = cv.fit_transform(train_data['Description'])
X_val_count = cv.transform(val_data['Description'])
X_test_count = cv.transform(test_data['Description'])

y_train = train_data['Category']
y_val = val_data['Category']
y_test = test_data['Category']

import time
# Function to train and evaluate Linear SVC
def train_and_evaluate_svc(X_train, y_train, X_val, y_val, model_name):
    # Initializing
    model = LinearSVC(max_iter=10000)

    # Record training time
    start_time = time.time()
    model.fit(X_train, y_train)
    training_time = time.time() - start_time

    # Record inference time
    start_time = time.time()
    predictions = model.predict(X_val)
    inference_time = time.time() - start_time

    accuracy = accuracy_score(y_val, predictions)
    f1 = f1_score(y_val, predictions, average='macro')
    conf_matrix = confusion_matrix(y_val, predictions)
    report = classification_report(y_val, predictions, target_names=model.classes_, output_dict=True)

    print(f"{model_name}:")
    print(f"Accuracy: {accuracy}")
    print("\nF1 Score for Each Class:")
    for class_name, metrics in report.items():
        if class_name in model.classes_:
            print(f"  {class_name}: F1 Score = {metrics['f1-score']}")
    print(f"Macro F1 Score: {f1}")
    print(f"Training Time: {training_time:.4f} seconds")
    print(f"Inference Time: {inference_time:.4f} seconds")
    print("Confusion Matrix:\n", conf_matrix)
    print("-" * 50)

    # Plot confusion matrix
    plt.figure(figsize=(8, 6))
    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=model.classes_, yticklabels=model.classes_)
    plt.title(f"Confusion Matrix for {model_name}")
    plt.xlabel("Predicted")
    plt.ylabel("Actual")
    plt.show()

from sklearn.svm import LinearSVC
from sklearn.metrics import classification_report

linear_svc_model = LinearSVC(max_iter=5000)
train_and_evaluate_svc(X_train_count, y_train, X_test_count, y_test, "Linear SVC with Bag of Words")

# Train and evaluate models
# 1. SVM
#svm_model = SVC()
#train_and_evaluate_model(svm_model, X_train_count, y_train, X_test_count, y_test, "SVM with Count Vectorization")

"""Tf-Idf"""

import time
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.feature_extraction.text import TfidfVectorizer

tfidf_vectorizer = TfidfVectorizer(max_features=5000)
X_train_tfidf = tfidf_vectorizer.fit_transform(train_data['Description'])
X_val_tfidf = tfidf_vectorizer.transform(val_data['Description'])
X_test_tfidf = tfidf_vectorizer.transform(test_data['Description'])

y_train = train_data['Category']
y_val = val_data['Category']
y_test = test_data['Category']

import time
# Function to train and evaluate Linear SVC
def train_and_evaluate_svc(X_train, y_train, X_val, y_val, model_name):
    # Initializing
    model = LinearSVC(max_iter=10000)

    # Record training time
    start_time = time.time()
    model.fit(X_train, y_train)
    training_time = time.time() - start_time

    # Record inference time
    start_time = time.time()
    predictions = model.predict(X_val)
    inference_time = time.time() - start_time

    accuracy = accuracy_score(y_val, predictions)
    f1 = f1_score(y_val, predictions, average='macro')
    conf_matrix = confusion_matrix(y_val, predictions)
    report = classification_report(y_val, predictions, target_names=model.classes_, output_dict=True)

    print(f"{model_name}:")
    print(f"Accuracy: {accuracy}")
    print("\nF1 Score for Each Class:")
    for class_name, metrics in report.items():
        if class_name in model.classes_:
            print(f"  {class_name}: F1 Score = {metrics['f1-score']}")
    print(f"Macro F1 Score: {f1}")
    print(f"Training Time: {training_time:.4f} seconds")
    print(f"Inference Time: {inference_time:.4f} seconds")
    print("Confusion Matrix:\n", conf_matrix)
    print("-" * 50)

    # Plot confusion matrix
    plt.figure(figsize=(8, 6))
    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=model.classes_, yticklabels=model.classes_)
    plt.title(f"Confusion Matrix for {model_name}")
    plt.xlabel("Predicted")
    plt.ylabel("Actual")
    plt.show()

train_and_evaluate_svc(X_train_tfidf, y_train, X_test_tfidf, y_test, "Linear SVM with TF-IDF")

"""N-grams(bigrams)"""

# Feature Engineering Technique 3: Word-based Bigrams (n-grams)
ngram_vectorizer = CountVectorizer(ngram_range=(1, 2), max_features=5000)
X_train_ngram = ngram_vectorizer.fit_transform(train_data['Description'])
X_val_ngram = ngram_vectorizer.transform(val_data['Description'])
X_test_ngram = ngram_vectorizer.transform(test_data['Description'])

import time
# Function to train and evaluate Linear SVC
def train_and_evaluate_svc(X_train, y_train, X_val, y_val, model_name):
    # Initializing
    model = LinearSVC(max_iter=10000)

    # Record training time
    start_time = time.time()
    model.fit(X_train, y_train)
    training_time = time.time() - start_time

    # Record inference time
    start_time = time.time()
    predictions = model.predict(X_val)
    inference_time = time.time() - start_time

    accuracy = accuracy_score(y_val, predictions)
    f1 = f1_score(y_val, predictions, average='macro')
    conf_matrix = confusion_matrix(y_val, predictions)
    report = classification_report(y_val, predictions, target_names=model.classes_, output_dict=True)

    print(f"{model_name}:")
    print(f"Accuracy: {accuracy}")
    print("\nF1 Score for Each Class:")
    for class_name, metrics in report.items():
        if class_name in model.classes_:
            print(f"  {class_name}: F1 Score = {metrics['f1-score']}")
    print(f"Macro F1 Score: {f1}")
    print(f"Training Time: {training_time:.4f} seconds")
    print(f"Inference Time: {inference_time:.4f} seconds")
    print("Confusion Matrix:\n", conf_matrix)
    print("-" * 50)

    # Plot confusion matrix
    plt.figure(figsize=(8, 6))
    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=model.classes_, yticklabels=model.classes_)
    plt.title(f"Confusion Matrix for {model_name}")
    plt.xlabel("Predicted")
    plt.ylabel("Actual")
    plt.show()

train_and_evaluate_svc(X_train_ngram, y_train, X_test_ngram, y_test, "Linear SVM with Word-based Bigrams")