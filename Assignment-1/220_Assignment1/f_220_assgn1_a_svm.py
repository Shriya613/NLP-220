# -*- coding: utf-8 -*-
"""F_220_assgn1_A_SVM

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11SzAwSovRG30FNmWc4oCuuF4-6oQE5-d

N-grams (bi-grams)
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
import sklearn.linear_model
import sklearn.metrics

#Binary classification
df = pd.read_csv('/content/small_books_rating.csv')

df.head()

list(df.columns)

# Fill missing values in text columns with an empty string
df['review/text'] = df['review/text'].fillna("")
df['review/summary'] = df['review/summary'].fillna("")
df['Title'] = df['Title'].fillna("Unknown Title")

# For any numerical columns with missing values, you could use the mean or median
# Example: df['some_numeric_column'] = df['some_numeric_column'].fillna(df['some_numeric_column'].mean())

# Verify there are no remaining missing values
print(df.isnull().sum())

df = df[(df['review/score'] <= 2) | (df['review/score'] >= 4)]

df['label'] = df['review/score'].apply(lambda x: 1 if x >= 4 else 0)

X = df['review/text']
y = df['label']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42, shuffle=True)

#Feature Engineering - N-grams (bi-grams)
from sklearn.feature_extraction.text import CountVectorizer
vectorizer = CountVectorizer(ngram_range=(1, 2), max_features=5000)
X_train_vec = vectorizer.fit_transform(X_train)
X_test_vec = vectorizer.transform(X_test)

import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix

from sklearn.metrics import accuracy_score, f1_score, confusion_matrix
from time import time

def evaluate_model(model, X_train, X_test, y_train, y_test):
    start_train = time()
    model.fit(X_train, y_train)
    end_train = time()
    training_time = end_train - start_train

    start_pred = time()
    y_pred = model.predict(X_test)
    end_pred = time()
    inference_time = end_pred - start_pred

    accuracy = accuracy_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred, average='macro')
    f1_each_class = f1_score(y_test, y_pred, average = None)
    conf_matrix = confusion_matrix(y_test, y_pred)

    print(f"Model: {model.__class__.__name__}")
    print(f"Accuracy: {accuracy:.4f}")
    print(f"F1 Score (for each class): {f1_each_class}")
    print(f"Macro F1 Score: {f1:.4f}")
    print(f"Training Time: {training_time:.4f} seconds")
    print(f"Inference Time: {inference_time:.4f} seconds")
    print(f"Confusion Matrix:\n{conf_matrix}")
    print("-" * 40)

    plt.figure(figsize=(6,4))
    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)
    plt.title(f"Confusion Matrix for {model.__class__.__name__}")
    plt.xlabel("Predicted")
    plt.ylabel("Actual")
    plt.show()

    return accuracy, f1, training_time, inference_time

# Initialize models
from sklearn.svm import SVC
svm_model = SVC()

# Evaluate model
ngram_results = evaluate_model(svm_model, X_train_vec, X_test_vec, y_train, y_test)

sns.countplot(x=y)
plt.title('Class Distribution')
plt.xlabel('Class')
plt.ylabel('Frequency')
plt.show()

results_df = pd.DataFrame({
    'Model': ['SVM (N-Grams)'],
    'Accuracy': [ngram_results[0]],
    'Macro F1 Score': [ngram_results[1]],
    'Training Time (s)': [ngram_results[2]],
    'Inference Time (s)': [ngram_results[3]]
})

print(results_df)

"""Bag-of-Words"""

df = df[(df['review/score'] <= 2) | (df['review/score'] >= 4)]
df['label'] = df['review/score'].apply(lambda x: 1 if x >= 4 else 0)
X = df['review/text']
y = df['label']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42, shuffle=True)

from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
def evaluate_model(model, X_train, X_test, y_train, y_test):
    start_train = time()
    model.fit(X_train, y_train)
    end_train = time()
    training_time = end_train - start_train

    start_pred = time()
    y_pred = model.predict(X_test)
    end_pred = time()
    inference_time = end_pred - start_pred

    accuracy = accuracy_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred, average='macro')
    f1_each_class = f1_score(y_test, y_pred, average = None)
    conf_matrix = confusion_matrix(y_test, y_pred)

    print(f"Model: {model.__class__.__name__}")
    print(f"Accuracy: {accuracy:.4f}")
    print(f"F1 Score (for each class): {f1_each_class}")
    print(f"Macro F1 Score: {f1:.4f}")
    print(f"Training Time: {training_time:.4f} seconds")
    print(f"Inference Time: {inference_time:.4f} seconds")
    print(f"Confusion Matrix:\n{conf_matrix}")
    print("-" * 40)

    plt.figure(figsize=(6,4))
    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)
    plt.title(f"Confusion Matrix for {model.__class__.__name__}")
    plt.xlabel("Predicted")
    plt.ylabel("Actual")
    plt.show()

    return accuracy, f1, training_time, inference_time

# Bag of Words (BOW) feature extraction
from sklearn.feature_extraction.text import CountVectorizer
bow_vectorizer = CountVectorizer(max_features=5000)
X_train_bow = bow_vectorizer.fit_transform(X_train)
X_test_bow = bow_vectorizer.transform(X_test)

#Initialize models
from sklearn.svm import SVC
svm_model = SVC()

print("Evaluating Naive Bayes with BOW Features")
bow_results = evaluate_model(svm_model, X_train_bow, X_test_bow, y_train, y_test)

# Plot class distribution
sns.countplot(x=y)
plt.title('Class Distribution')
plt.xlabel('Class')
plt.ylabel('Frequency')
plt.show()

# Store results in DataFrame
results_df = pd.DataFrame({
    'Model': ['Naive Bayes (BOW)'],
    'Accuracy': [bow_results[0]],
    'Macro F1 Score': [bow_results[1]],
    'Training Time (s)': [bow_results[2]],
    'Inference Time (s)': [bow_results[3]]
})

print(results_df)

"""Tf-Idf"""

# Step 3: Feature Engineering - TF-IDF
from sklearn.feature_extraction.text import TfidfVectorizer
tfidf_vectorizer = TfidfVectorizer(max_features=5000)
X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)
X_test_tfidf = tfidf_vectorizer.transform(X_test)

# Step 5: Model Training and Evaluation
def evaluate_model(model, X_train, X_test, y_train, y_test):
    start_train = time()
    model.fit(X_train, y_train)
    end_train = time()
    training_time = end_train - start_train

    start_pred = time()
    y_pred = model.predict(X_test)
    end_pred = time()
    inference_time = end_pred - start_pred

    accuracy = accuracy_score(y_test, y_pred)
    f1_each_class = f1_score(y_test, y_pred, average = None)
    f1 = f1_score(y_test, y_pred, average='macro')
    conf_matrix = confusion_matrix(y_test, y_pred)

    print(f"Model: {model.__class__.__name__}")
    print(f"Accuracy: {accuracy:.4f}")
    print(f"F1 Score (for each class): {f1_each_class}")
    print(f"Macro F1 Score: {f1:.4f}")
    print(f"Training Time: {training_time:.4f} seconds")
    print(f"Inference Time: {inference_time:.4f} seconds")
    print(f"Confusion Matrix:\n{conf_matrix}")
    print("-" * 40)

    plt.figure(figsize=(6,4))
    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)
    plt.title(f"Confusion Matrix for {model.__class__.__name__}")
    plt.xlabel("Predicted")
    plt.ylabel("Actual")
    plt.show()

    return accuracy, f1, training_time, inference_time

from sklearn.svm import SVC
svm_model = SVC()

print("Evaluating Naive Bayes with TF-IDF Features")
tfidf_results = evaluate_model(svm_model, X_train_tfidf, X_test_tfidf, y_train, y_test)

sns.countplot(x=y)
plt.title('Class Distribution')
plt.xlabel('Class')
plt.ylabel('Frequency')
plt.show()

results_df = pd.DataFrame({
    'Model': [ 'Naive Bayes (TF-IDF)'],
    'Accuracy': [tfidf_results[0]],
    'Macro F1 Score': [tfidf_results[1]],
    'Training Time (s)': [tfidf_results[2]],
    'Inference Time (s)': [tfidf_results[3]]
})

print(results_df)

